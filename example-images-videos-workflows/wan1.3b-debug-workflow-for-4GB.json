{"last_node_id":60,"last_link_id":132,"nodes":[{"id":57,"type":"SkipLayerGuidanceDiT","pos":[863.2327880859375,-189.85679626464844],"size":[210,178],"flags":{},"order":8,"mode":4,"inputs":[{"name":"model","localized_name":"model","type":"MODEL","link":128}],"outputs":[{"name":"MODEL","localized_name":"MODEL","type":"MODEL","links":[123],"slot_index":0}],"properties":{"Node name for S&R":"SkipLayerGuidanceDiT"},"widgets_values":["9, 10","9, 10",3,0.01,0.3,0]},{"id":51,"type":"CLIPLoaderGGUF","pos":[518.1205444335938,148.8343963623047],"size":[315,82],"flags":{},"order":0,"mode":0,"inputs":[],"outputs":[{"name":"CLIP","localized_name":"CLIP","type":"CLIP","links":[102,103],"slot_index":0}],"properties":{"Node name for S&R":"CLIPLoaderGGUF"},"widgets_values":["umt5xxl_fp32-q2_k.gguf","wan"]},{"id":52,"type":"CFGZeroStar","pos":[1122.966064453125,-185.4257354736328],"size":[241.79998779296875,26],"flags":{},"order":9,"mode":0,"inputs":[{"name":"model","localized_name":"model","type":"MODEL","link":129}],"outputs":[{"name":"patched_model","localized_name":"patched_model","type":"MODEL","links":[115],"slot_index":0}],"properties":{"Node name for S&R":"CFGZeroStar"},"widgets_values":[]},{"id":28,"type":"SaveAnimatedWEBP","pos":[1463.1033935546875,-190.3585968017578],"size":[635.0166015625,756.7459106445312],"flags":{},"order":14,"mode":0,"inputs":[{"name":"images","localized_name":"images","type":"IMAGE","link":126}],"outputs":[],"properties":{},"widgets_values":["ComfyUI",16,false,100,"fastest"]},{"id":56,"type":"TeaCache","pos":[1090.77001953125,-120.34005737304688],"size":[315,106],"flags":{},"order":11,"mode":0,"inputs":[{"name":"model","localized_name":"model","type":"MODEL","link":115}],"outputs":[{"name":"model","localized_name":"model","type":"MODEL","links":[116],"slot_index":0}],"properties":{"Node name for S&R":"TeaCache"},"widgets_values":["wan2.1_t2v_1.3B",0.21,1]},{"id":39,"type":"VAELoader","pos":[520.677001953125,496.49053955078125],"size":[306.36004638671875,58],"flags":{},"order":1,"mode":0,"inputs":[],"outputs":[{"name":"VAE","localized_name":"VAE","type":"VAE","links":[125],"slot_index":0}],"properties":{"Node name for S&R":"VAELoader"},"widgets_values":["wan_2.1_vae.safetensors"]},{"id":55,"type":"KSamplerAdvanced","pos":[1126.32861328125,32.6392822265625],"size":[256.2142028808594,334],"flags":{},"order":12,"mode":0,"inputs":[{"name":"model","localized_name":"model","type":"MODEL","link":116},{"name":"positive","localized_name":"positive","type":"CONDITIONING","link":112},{"name":"negative","localized_name":"negative","type":"CONDITIONING","link":113},{"name":"latent_image","localized_name":"latent_image","type":"LATENT","link":118}],"outputs":[{"name":"LATENT","localized_name":"LATENT","type":"LATENT","links":[124],"slot_index":0}],"properties":{"Node name for S&R":"KSamplerAdvanced"},"widgets_values":["enable",199,"increment",12,6.5,"euler","simple",4,10000,"disable"]},{"id":54,"type":"KSamplerAdvanced","pos":[852.9434814453125,32.40223693847656],"size":[255.10496520996094,334],"flags":{},"order":10,"mode":0,"inputs":[{"name":"model","localized_name":"model","type":"MODEL","link":123},{"name":"positive","localized_name":"positive","type":"CONDITIONING","link":106},{"name":"negative","localized_name":"negative","type":"CONDITIONING","link":107},{"name":"latent_image","localized_name":"latent_image","type":"LATENT","link":117}],"outputs":[{"name":"LATENT","localized_name":"LATENT","type":"LATENT","links":[118],"slot_index":0}],"properties":{"Node name for S&R":"KSamplerAdvanced"},"widgets_values":["enable",199,"increment",12,4,"euler_ancestral","simple",0,4,"disable"]},{"id":6,"type":"CLIPTextEncode","pos":[522.8845825195312,-190.01649475097656],"size":[304.4969177246094,150.89210510253906],"flags":{},"order":5,"mode":0,"inputs":[{"name":"clip","localized_name":"clip","type":"CLIP","link":102}],"outputs":[{"name":"CONDITIONING","localized_name":"CONDITIONING","type":"CONDITIONING","links":[106,112],"slot_index":0}],"title":"CLIP Text Encode (Positive Prompt)","properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["Extreme closeup view, Lady is standing in shallow water, wearing white dress, holding a legendary steel sword. Excalibur movie of Lady standing.\n\nCloseup of Lady standing in water, holding sword\n\n "],"color":"#232","bgcolor":"#353"},{"id":40,"type":"EmptyHunyuanLatentVideo","pos":[876.8009033203125,412.5660095214844],"size":[210,130],"flags":{},"order":2,"mode":0,"inputs":[],"outputs":[{"name":"LATENT","localized_name":"LATENT","type":"LATENT","links":[117],"slot_index":0}],"properties":{"Node name for S&R":"EmptyHunyuanLatentVideo"},"widgets_values":[384,576,33,1]},{"id":48,"type":"VAEDecodeTiled","pos":[1121.5211181640625,408.84197998046875],"size":[270.4435119628906,151.3353271484375],"flags":{},"order":13,"mode":0,"inputs":[{"name":"samples","localized_name":"samples","type":"LATENT","link":124},{"name":"vae","localized_name":"vae","type":"VAE","link":125}],"outputs":[{"name":"IMAGE","localized_name":"IMAGE","type":"IMAGE","links":[126],"slot_index":0}],"properties":{"Node name for S&R":"VAEDecodeTiled"},"widgets_values":[160,64,64,4]},{"id":37,"type":"UNETLoader","pos":[514.2470703125,265.6011657714844],"size":[324.56378173828125,82],"flags":{},"order":3,"mode":0,"inputs":[],"outputs":[{"name":"MODEL","localized_name":"MODEL","type":"MODEL","links":[132],"slot_index":0}],"properties":{"Node name for S&R":"UNETLoader"},"widgets_values":["wan13fp16native.safetensors","default"]},{"id":58,"type":"LoraLoaderModelOnly","pos":[520.43994140625,382.7991943359375],"size":[314.087890625,82],"flags":{},"order":7,"mode":4,"inputs":[{"name":"model","localized_name":"model","type":"MODEL","link":132}],"outputs":[{"name":"MODEL","localized_name":"MODEL","type":"MODEL","links":[128,129],"slot_index":0}],"properties":{"Node name for S&R":"LoraLoaderModelOnly"},"widgets_values":["wan21\\wan1.3bcfgdistill-videov40.safetensors",0.2]},{"id":7,"type":"CLIPTextEncode","pos":[526.7003784179688,-0.13482330739498138],"size":[305.7098388671875,114.72174072265625],"flags":{},"order":6,"mode":0,"inputs":[{"name":"clip","localized_name":"clip","type":"CLIP","link":103}],"outputs":[{"name":"CONDITIONING","localized_name":"CONDITIONING","type":"CONDITIONING","links":[107,113],"slot_index":0}],"title":"CLIP Text Encode (Negative Prompt)","properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["anime, 3d, line drawing, artwork, manga, cartoon 过曝，静止不动的画面, 静态，细节模糊不清，作品，画作，画面，静止，低质量，JPEG压缩残留"],"color":"#322","bgcolor":"#533"},{"id":60,"type":"Note","pos":[152.43955993652344,-153.66842651367188],"size":[317.220703125,598.5787963867188],"flags":{},"order":4,"mode":0,"inputs":[],"outputs":[],"properties":{},"widgets_values":["BASIC DEBUGGING WORKFLOW, AMD 4GB VRAM: text2vid\n================================================ \n\n16 GB System RAM and higher required.\nstart with just 1 frame (single picture) for testing. if that doesn't work then nothing will\n\nSmall short test videos (256x384)x33 should finish in 3 to 5 minutes, but you'll need to render at least 384x576 to get normal realistic results that follow the actual training data. It will take approximately forever. (or won't even work)\n\nVAE Decode (tile_size) is important, keep an eye on GPU VRAM usage, default of 160 or 192 should be fine for 4GB. Set tile_size to 128 or even lower if trying 512x512 or higher with 33 or more frames. Untested and probably doesn't work.\n\nWAN21 img2Vid with start/end frames can crash during VAE encode node.  Completely running out system swap, DRAM and VRAM at the same time might crash and require a reboot to reset the GPU state. Known issue. Likely won't work\n\nc:\\PathToZluda\\zluda.exe -- python main.py --disable-cuda --use-quad-cross-attention --disable-smart-memory --cache-lru 0 --reserve-vram 0.1 --force-fp16 --fp16-unet --fp16-vae --novram\n\nThese debug options sometimes help in low VRAM scenarios.  Haven't had much time to test if they still actually work or have been deprecated.  Good luck, and thank you for testing.  If you have any questions ask on the Github issues page.\nhttps://github.com/advanced-lvl-up/Rx470-Vega10-Rx580-gfx803-gfx900-fix-AMD-GPU\n\n---- KSampler: noise_seed, number of steps, \n & scheduler should match. And 'end_at_step' for sampler #1 is the 'start_at_step' for sampler #2.\n\nNodes used: Teacache & GGUF connector from:\nhttps://github.com/welltop-cn/ComfyUI-TeaCache\nhttps://github.com/calcuis/gguf"],"color":"#323","bgcolor":"#535"}],"links":[[102,51,0,6,0,"CLIP"],[103,51,0,7,0,"CLIP"],[106,6,0,54,1,"CONDITIONING"],[107,7,0,54,2,"CONDITIONING"],[112,6,0,55,1,"CONDITIONING"],[113,7,0,55,2,"CONDITIONING"],[115,52,0,56,0,"MODEL"],[116,56,0,55,0,"MODEL"],[117,40,0,54,3,"LATENT"],[118,54,0,55,3,"LATENT"],[123,57,0,54,0,"MODEL"],[124,55,0,48,0,"LATENT"],[125,39,0,48,1,"VAE"],[126,48,0,28,0,"IMAGE"],[128,58,0,57,0,"MODEL"],[129,58,0,52,0,"MODEL"],[132,37,0,58,0,"MODEL"]],"groups":[],"config":{},"extra":{"ds":{"scale":0.7627768444386291,"offset":[30.70660393288739,311.66120044242007]}},"version":0.4}
